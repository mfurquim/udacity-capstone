\documentclass[10pt,twoside,twocolumn,nofonttune,a4paper,journal,compsoc,english,french,spanish]{IEEEtran}

\usepackage{cmap}
\usepackage{lmodern}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{indentfirst}
\usepackage[table]{xcolor}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{units}
\usepackage[english,hyperpageref]{backref}
\usepackage{bold-extra}
\usepackage[hyphens]{url}
\usepackage{eso-pic}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{minted}
\usepackage{bm}
\usepackage[framemethod=TikZ]{mdframed}
\usepackage{showexpl}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{tipa}
\usepackage{mathabx}
\usepackage{upgreek}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{ragged2e}
\usepackage{multicol}
\usepackage{lineno}
\usepackage{tabularx}
\usepackage{realboxes}
\usepackage{xpatch}


\providecommand{\tightlist}{%
	  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

\newcommand{\passthrough}[1]{#1}


\newcommand\bigzero{\makebox(0,0){\text{\huge0}}}
\renewcommand{\arraystretch}{1.618033988749894848204586834365638117720309179805762862135448}

\definecolor{NordBG}{HTML}{242933}              % nord00
% Polar Night
\definecolor{NordDarkBlack}{HTML}{2E3440}       % nord0
\definecolor{NordBlack}{HTML}{3B4252}           % nord1
\definecolor{NordMediumBlack}{HTML}{434C5e}     % nord2
\definecolor{NordBrightBlack}{HTML}{4C566A}     % nord3
\definecolor{NordBrightBlack10}{HTML}{616e88}   % nord3 + 10%
\definecolor{NordBrightBlack12}{HTML}{66738e}   % nord3 + 12%
% Snow Storm
\definecolor{NordWhite}{HTML}{D8DEE9}           % nord4
\definecolor{NordBrighterWhite}{HTML}{E5E9F0}   % nord5
\definecolor{NordBrightestWhite}{HTML}{ECEFF4}  % nord6
% Frost
\definecolor{NordCyan}{HTML}{8FBCBB}            % nord7
\definecolor{NordBrightCyan}{HTML}{88C0D0}      % nord8
\definecolor{NordBrightBlue}{HTML}{81A1C1}      % nord9
\definecolor{NordBlue}{HTML}{5E81AC}            % nord10
% Aurora
\definecolor{NordRed}{HTML}{BF616A}             % nord11
\definecolor{NordOrange}{HTML}{D08770}          % nord12
\definecolor{NordYellow}{HTML}{EBCB8B}          % nord13
\definecolor{NordGreen}{HTML}{A3BE8C}           % nord14
\definecolor{NordMagenta}{HTML}{B48EAD}         % nord15

\lstset{%
	basicstyle=\ttfamily,
	breaklines = true,
	backgroundcolor=\color{NordMagenta},
}

\makeatletter
\xpretocmd\lstinline
{%
	\bgroup\fboxsep=0pt
	\Colorbox{NordWhite}\bgroup\kern-\fboxsep\vphantom{\ttfamily\char`\\y}%
	\appto\lst@DeInit{\kern-\fboxsep\egroup\egroup}%
}{}{}
\makeatother

\newcommand\MYhyperrefoptions{%
bookmarks=true,bookmarksnumbered=true,%
pdfpagemode={UseOutlines},plainpages=false,pdfpagelabels=true,%
colorlinks=true,linkcolor={black},citecolor={black},pagecolor={black},%
urlcolor={black},%
pdftitle={Machine Learning Engineer Nanodegree, Capstone Proposal},%
pdfsubject={Capstone Proposal},%<!CHANGE!
pdfauthor={Mateus M. F. Mendonça},%
pdfkeywords={Machine Learning Engineer, Nanodegree, Udacity, Principal Component Analysis, PCA}%
}

% \newmdenv[tikzsetting={fill=NordDarkBlack,},settings={\tikzset{every picture/.style={opacity=0.1}}}]{myenvironment}

\mdfdefinestyle{code}{%
	innertopmargin=0pt,
	innerbottommargin=12pt,
	skipabove=\baselineskip,
	skipbelow=\baselineskip,
	leftmargin=6pt,
	rightmargin=6pt,
	innerleftmargin=3,
	innerrightmargin=2,
	rightline=true,
	frametitlerule=true,
	backgroundcolor=NordDarkBlack,
	frametitlerulewidth=0.2pt,
	frametitlealignment=\center,
	frametitleaboveskip=5pt,
	frametitlebelowskip=3pt,
	frametitlebackgroundcolor=NordBrightestWhite,
	align=center,
	linecolor=NordWhite,
	linewidth=1pt,
	shadow=false,
	shadowsize=3pt,
	shadowcolor=NordBG,
	roundcorner=3pt
}

\mdfdefinestyle{output}{%
	innertopmargin=0pt,
	innerbottommargin=12pt,
	skipabove=\baselineskip,
	skipbelow=\baselineskip,
	leftmargin=6pt,
	rightmargin=6pt,
	innerleftmargin=3,
	innerrightmargin=2,
	rightline=true,
	frametitlerule=true,
	backgroundcolor=white,
	frametitlerulewidth=0.2pt,
	frametitlealignment=\center,
	frametitleaboveskip=5pt,
	frametitlebelowskip=3pt,
	frametitlebackgroundcolor=NordBrightestWhite,
	align=center,
	linecolor=NordWhite,
	linewidth=1pt,
	shadow=false,
	shadowsize=3pt,
	shadowcolor=NordBG,
	roundcorner=3pt
}

\begin{document}

% \usemintedstyle{nord}

\setminted[python]{
	autogobble,
	fontsize=\scriptsize,
	frame=single,
	highlightlines=0,
	labelposition=all,
	linenos=false,
	numbers=none,
	obeytabs=false,
	python3=true,
	resetmargins=true,
	rulecolor=NordBG,
	samepage=true,
	tabsize=4,
	texcomments=true,
	breaksymbolleft=\textcolor{NordBrightBlack}{\tiny$\hookrightarrow$}
}


\title{\textbf{Machine Learning Engineer Nanodegree}\\
        Capstone Proposal}

\author{Mateus Medeiros Furquim Mendonça - mateus@mfurquim.dev}

\markboth{Capstone Proposal - \today}% June 11$^{\lowercase{th}}$\hskip-1pt, 2022}
{M. Mendonça: Capstone Proposal}

% \IEEEcompsoctitleabstractindextext{%
%     \begin{abstract}
% 		The relationship between reduction of dimensionality with from a dataset with training performance and prediction accuracy.
%     \end{abstract}

%     \begin{IEEEkeywords}
% 		Principal Component Analysis, PCA, Arvato, Kaggle, Udacity
%     \end{IEEEkeywords}
% }

\maketitle

\IEEEdisplaynontitleabstractindextext

\hypertarget{domain-background}{%
\section{Domain Background}\label{domain-background}}

One of the principal steps in the machine learning process is the
feature engineering. It falls into the Data Preparation step in the
CRISP-DM, which is usually the most time consuming
(60\%\textasciitilde70\% of time in overall
project)\cite{sarkar2017practical}. In feature engineering there are two
different approaches: \textbf{feature selection} and \textbf{feature
extraction}. Principal Component Analysis (PCA) is a process of feature
extraction to reduce the dimensionality of the data by understanding the
individual significance for a feature on the result of the
outcome\cite{shlens2014tutorial}. If two features are directly related
and change at the same rate, then there is no need to have both of them
to predict the output. For instance, if there are two features which
measure a phenomenon, one in meters and another one in inches, they are
measuring the same thing but in different scales. So there would only be
need to keep one of them.

\hypertarget{problem-statement}{%
\section{Problem Statement}\label{problem-statement}}

It is expected that the Principal Component Analysis technique will
improve the time of training and accuracy of prediction. This project
aims to compare the performance of the model with and without applying
the PCA techinque for reduction of dimensionality. By the end, there
should be a better understanding on the relationship between the
percentage of variance retained and the performance of training and
prediction.

Furthermore, this project will also compete in the \emph{Udacity+Arvato:
Identify Customer Segments Kaggle
Competition}\cite{arvato_kaggle_competition}, The goal of the
competition is to help a mail-order company, which sells organic
products, to increase efficiency in the customer acquisition process. To
figure out which people in Germany are most likely to be new customers,
the attributes of existing clients are analyzed and matched against a
bigger data set that includes attributes for people in the country.

\hypertarget{datasets-and-inputs}{%
\section{Datasets and Inputs}\label{datasets-and-inputs}}

The data set used in this project will be the Arvato's data set provided
by the course in the Kaggle Competition\cite{arvato_kaggle_competition},
The Arvato's data set is a compilation of financial data from their
customers and the Germany demographic data. The customers data set has
369 features (columns) and almost 200 thousand observations (rows),
whereas the Germany data set contains 366 features (columns) and almost
900 thousand observations (rows).

Those features are separated in the following different levels of
information: (\textbf{person}) description of the person and his/her
habits; (\textbf{household}) number of people, estimated net income, and
the structure of the house; (\textbf{building}) number of households and
type of building; (\textbf{microcell}) CAMEO\footnote{The CAMEO profiles
  contain socio-demographic and lifestyle data at microcell level based
  on parameters such as age, education, income, and general interests.}
typology, number of family houses in the cell, and share of car owners;
(\textbf{transactional}) unique activity data regarding the mail-order
activity of consumers; (\textbf{postcode}) distance to next metropole
and density of inhabitants; (\textbf{automobile}) share of cars
differentiated; and (\textbf{community}) share of unemployed person and
number of inhabitants in the community.

\hypertarget{solution-statement}{%
\section{Solution Statement}\label{solution-statement}}

The proposed solution is to understand the relationship between all 369
features and the likelihood of a German citizen being a customer.
Because of the nature of the problem - i.e., having labeled data - we
will train a supervised model to predict a potential customer and help
the marketing team to focus their effort on them.

Furthermore, a Principal Component Analysis will be applied on the
training set. A total of \(K\) dimensions will be kept such that at
least 85\% of the variance is retained. The model will be trained using
\(k \in \left[K,m\right]\) features, where \(m\) is the total number of
features (366). For each dimension reduction, there will be a
corresponding plot for the model's training and prediction performance.

At the end, there should be a clear visualization on how the
dimensionality reduction affects the training speed and prediction
accuracy.

\hypertarget{benchmark-model}{%
\section{Benchmark Model}\label{benchmark-model}}

For this problem, the model without PCA will be used as benchmark to
compare the solution with different number of dimensions and percentage
of variance retained. The best model will be submited to the
aforementioned kaggle competition and compared with the current
leaderboard.

\hypertarget{evaluation-metrics}{%
\section{Evaluation Metrics}\label{evaluation-metrics}}

Training performance will be measured by speed and prediction results
are going to be evaluated using the area under the ROC curve\footnote{The
  Receiver Operating Characteristic curve is created by plotting the
  true positive rate against the false positive rate at various
  threshold settings.}. Another secondary evaluation metric will also be
used just for informative purpose: the F1 Score - which is defined as
the harmonic mean of precision and recall. It is specially useful when
having imbalanced data because it takes into account both errors (false
positives or false negatives)\cite{Korstanje2021F1Score}.

\hypertarget{project-design}{%
\section{Project Design}\label{project-design}}

\hypertarget{explore-and-process-data}{%
\subsection{Explore and Process Data}\label{explore-and-process-data}}

After downloading the data from the Arvato kaggle
competition\cite{arvato_kaggle_competition}, it comes the Exploratory
Data Analysis (EDA) step. In the EDA, the data will be cleaned,
explored, and pre-processed. The NaN (Not a Number) and missing values
are going to be treated accordingly to the feature type (binary,
categorical, continuous etc.) and context. Further features might be
engineered in order to consolidate one or more features.

Most machine learning models expect standardized data values. Therefore,
this step might also involve normalizing and converting the format of
the data. In addition, the data will be split into training\footnote{Training
  dataset is used to train the model.}, validation\footnote{Validation
  dataset is used for model tuning and selection.} and test\footnote{Test
  dataset is used after training for evaluation of the model} data sets.

Visualize data.

\hypertarget{modeling}{%
\subsection{Modeling}\label{modeling}}

This step will focus on developing the model. A model will be selected
and trained using the training dataset. After creating the model, the
time of training is going to be recorded and the model will be evaluated
and validated by the chosen metric - \textbf{Area Under the ROC Curve}
(AUC) - against the validation data set.

\hypertarget{principal-component-analysis}{%
\subsection{Principal Component
Analysis}\label{principal-component-analysis}}

When the first model (benchmark model) is developed and evaluated, the
next step will be to apply the PCA technique to reduce the number of
dimensions such that at least 85\% of the variance is retained. For each
dimension reduction, a new model will be trained and evaluated in order
to get the corresponding computation time and the AUC.
% \section{Source code}

\bibliographystyle{IEEEtran}
\bibliography{proposal.bib}

% \appendices

\end{document}

